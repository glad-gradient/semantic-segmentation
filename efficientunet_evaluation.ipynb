{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from pandas import read_csv, merge, concat\n",
    "from skimage.io import imread\n",
    "from cv2 import resize\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from segmentation_models import losses\n",
    "from keras.models import load_model\n",
    "\n",
    "from efficientnet.keras import EfficientNetB0\n",
    "from efficientnet.keras import preprocess_input\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "STEPS_PER_EPOCH = 1000\n",
    "RANDOM_SEED = 10000\n",
    "IMG_SIZE = 384\n",
    "LEARNING_RATE = 0.00001\n",
    "ALPHA = 10.0\n",
    "\n",
    "\n",
    "PATH_CHECKPOINT = 'models'\n",
    "MODEL = 'efficientunet_256_1580639531_384_1580712972.hdf5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_focal_loss = losses.BinaryFocalLoss(alpha=ALPHA)\n",
    "dice_loss = losses.DiceLoss(smooth=1)\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
    "\n",
    "\n",
    "def binary_focal_dice_loss(y_true, y_pred):\n",
    "    return binary_focal_loss(y_true, y_pred) + dice_loss(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return\n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "\n",
    "def masks_as_image(in_mask_list):\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    all_masks = np.zeros((768, 768), dtype=np.int16)\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks += rle_decode(mask)\n",
    "    return all_masks\n",
    "\n",
    "\n",
    "def make_image_generator(in_df, batch_size=BATCH_SIZE, preprocessing_function=None):\n",
    "    all_batches = list(in_df.groupby('ImageId'))\n",
    "    out_rgb = []\n",
    "    out_mask = []\n",
    "    while True:\n",
    "        for c_img_id, c_masks in all_batches:\n",
    "            rgb_path = os.path.join(train_image_dir, c_img_id)\n",
    "            _img = imread(rgb_path)           \n",
    "            _img = resize(_img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "            masks_as_img = masks_as_image(c_masks['EncodedPixels'].values)\n",
    "            _mask = resize(masks_as_img, (IMG_SIZE, IMG_SIZE))\n",
    "            _mask = np.expand_dims(_mask, -1)\n",
    "\n",
    "            _img = _img.astype(np.float32)\n",
    "            _mask = _mask.astype(np.uint8)\n",
    "\n",
    "            if preprocessing_function:\n",
    "                _img = preprocessing_function(_img)\n",
    "\n",
    "            out_rgb += [_img]\n",
    "            out_mask += [_mask]\n",
    "            if len(out_rgb) >= batch_size:\n",
    "                yield np.stack(out_rgb, 0), np.stack(out_mask, 0)\n",
    "                out_rgb, out_mask = [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(_train_image_dir, _exclude_list, n_train=0.8, balanced=False):\n",
    "    masks = read_csv(os.path.join(data_dir, 'train_ship_segmentations_v2.csv.zip'))\n",
    "\n",
    "    masks = masks[~masks['ImageId'].isin(_exclude_list)]\n",
    "\n",
    "    masks['ships'] = masks['EncodedPixels'].map(lambda row: 1 if isinstance(row, str) else 0)\n",
    "    unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\n",
    "\n",
    "    unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x > 0 else 0.0)\n",
    "\n",
    "    n_train_split = int(n_train * len(unique_img_ids))\n",
    "\n",
    "    train_ids = unique_img_ids.iloc[:n_train_split]\n",
    "    valid_ids = unique_img_ids.iloc[n_train_split:]\n",
    "\n",
    "    if balanced:\n",
    "        ones = train_ids.loc[train_ids['has_ship'] == 1]\n",
    "        zeros = train_ids.loc[train_ids['has_ship'] == 0]\n",
    "        zeros = zeros.sample(len(ones))\n",
    "        train_ids = concat([ones, zeros])\n",
    "\n",
    "    masks.drop(['ships'], axis=1, inplace=True)\n",
    "\n",
    "    _train_df = merge(masks, train_ids)\n",
    "    _valid_df = merge(masks, valid_ids)\n",
    "\n",
    "    return _train_df, _valid_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_list = ['6384c3e78.jpg', '13703f040.jpg', '14715c06d.jpg', '33e0ff2d5.jpg',\n",
    "                    '4d4e09f2a.jpg', '877691df8.jpg', '8b909bb20.jpg', 'a8d99130e.jpg',\n",
    "                    'ad55c3143.jpg', 'c8260c541.jpg', 'd6c7f17c7.jpg', 'dc3e7c901.jpg',\n",
    "                    'e44dffe88.jpg', 'ef87bad36.jpg', 'f083256d8.jpg', '66049e4ea.jpg']  # corrupted images\n",
    "\n",
    "with open('config.json', 'r') as file:\n",
    "    configs = json.load(file)\n",
    "\n",
    "data_dir = configs[\"DATA_DIRECTORY\"]\n",
    "train_image_dir = os.path.join(data_dir, 'train_v2')\n",
    "\n",
    "train_df, test_df = preprocess_data(train_image_dir, exclude_list)\n",
    "\n",
    "\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(f'models/{MODEL}', compile=False)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=LEARNING_RATE),\n",
    "    loss=binary_focal_dice_loss,\n",
    "    metrics=[dice_coef],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval_generator = make_image_generator(\n",
    "    train_df,\n",
    "    preprocessing_function=preprocess_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python37\\lib\\site-packages\\keras\\utils\\data_utils.py:718: UserWarning: An input could not be retrieved. It could be because a worker has died.We do not have any information on the lost sample.\n  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10607115924358368, 0.7279453873634338]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(train_eval_generator, steps=STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval_generator = make_image_generator(\n",
    "    test_df,\n",
    "    preprocessing_function=preprocess_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11424889415502548, 0.7290158867835999]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_eval_generator, steps=STEPS_PER_EPOCH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
